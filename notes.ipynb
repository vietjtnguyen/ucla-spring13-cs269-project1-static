{
 "metadata": {
  "name": "notes"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CS 269 - Project 1 - Notes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "import IPython.core.display\n",
      "\n",
      "def display_html(html):\n",
      "    IPython.core.display.display(IPython.core.display.HTML(data=html))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Quick Reference\n",
      "\n",
      "* [`scikit-learn` stable user guide](http://scikit-learn.org/stable/user_guide.html)\n",
      "* [`scikit-learn` stable documentation](http://scikit-learn.org/stable/modules/classes.html)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Summary\n",
      "\n",
      "I need to select three algorithms and three data sets. Right now I'm leaning towards the following three algorithms:\n",
      "\n",
      "* Random Forests\n",
      "* Support Vector Machines\n",
      "* k-Nearest-Neighbor\n",
      "* <del>AdaBoost with C4.5 Decision Trees</del>\n",
      "  * I decided not to used AdaBoost because it's only available in `scikit-learn` `0.14-git` and the current stable one is `0.13.1`\n",
      "\n",
      "I'm a bit weary of using SVM because I'm not sure I understand it as well as I should (especially the \"kernel trick\"). However, in the interest of diverse edification I feel like it should be included. With that in mind, I think one ensemble, one non-parametric, and one parametric is a good diversity.\n",
      "\n",
      "For datasets, I'm leaning towards the following three:\n",
      "\n",
      "* DIGITS: <http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits>\n",
      "* IRIS: <http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris>\n",
      "* GISETTE: <http://archive.ics.uci.edu/ml/datasets/Gisette>\n",
      "* MADELON: <http://archive.ics.uci.edu/ml/datasets/Madelon>\n",
      "* HAR: <http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones>\n",
      "* LETTER: <http://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/>\n",
      "\n",
      "The following were considered as well:\n",
      "\n",
      "* COVTYPE: <http://archive.ics.uci.edu/ml/datasets/Covertype>\n",
      "* ADULT: <http://archive.ics.uci.edu/ml/datasets/Adult>\n",
      "* OPPORTUNITY: <http://archive.ics.uci.edu/ml/datasets/OPPORTUNITY+Activity+Recognition>\n",
      "* DOROTHEA: <http://archive.ics.uci.edu/ml/datasets/Dorothea>\n",
      "* SECOM: <http://archive.ics.uci.edu/ml/datasets/SECOM>\n",
      "* Internet Advertisements: <http://archive.ics.uci.edu/ml/datasets/Internet+Advertisements>\n",
      "* <del>Communities and Crime: <http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime></del> this is a regression data set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Support Vector Machines\n",
      "\n",
      "Found a [good reference](http://www.cs.utah.edu/~piyush/teaching/13-9-print.pdf) for support vector machines which explains what the \"C value\" is. The SVM dual optimization formulation with slack variables is\n",
      "\n",
      "$$\n",
      "\\text{Minimize } f(w, b) = \\frac{\\|w\\|^2}{2} + C \\sum_{n=1}^{N} \\xi_n \\\\\\\\\n",
      "\\text{subject to } y_n(w^T x_n + b) \\geq 1 - \\xi_n, \\quad \\xi_n \\geq 0, \\quad n = 1, \\ldots, N \\\\\\\\\n",
      "\\begin{eqnarray}\n",
      "w, b &=& \\text{margin parameters} \\\\\\\\\n",
      "\\xi_n &=& \\text{slack variable for point } n \\\\\\\\\n",
      "C &=& \\text{term importance weight} \\\\\\\\\n",
      "\\end{eqnarray}\n",
      "$$\n",
      "\n",
      "The important thing to note is that a small $C$ prefers large margins (potentially allowing a large number of misclassified training examples) and a large $C$ prefers a small number of misclassified examples (at the expense of having a small margin)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Decision Trees\n",
      "\n",
      "From what I can tell, C4.5 decision trees is based off of ID3. It is ID3 extended to support continuous variables."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Cross Validation\n",
      "\n",
      "According to the 2006 paper,\n",
      "\n",
      "> For each test problem we randomly select 5000 cases for training and use the rest of the cases as a large final test set. We use 5-fold cross validation on the 5000 cases to obtain five trials. For each trial we use 4000 cases to train the different models, 1000 cases to calibrate the models and select the best parameters, and then report performance on the large final test set. We would like to run more trials, but this is a very expensive set of experiments. Fortunately, even with only five trials we are able to discern interesting differences between methods.\n",
      "\n",
      "My interpretation is that we follow the following steps:\n",
      "\n",
      "1. Combine all data (validation, training, test with labels).\n",
      "2. Shuffle data.\n",
      "3. Split the first 5000 off as a training set. The rest will be used for testing.\n",
      "4. Perform 5-fold cross validation.\n",
      "5. For each fold there are 4000 training samples and 1000 validation samples. For each fold, perform a grid search to find the best parameterization using the 4000 training samples and 1000 validation samples."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Specifications"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data Sets\n",
      "\n",
      "<table>\n",
      "    <tr>\n",
      "        <td>Data Set</td>\n",
      "        <td>Samples/Count/Size</td>\n",
      "        <td>Features/Attributes/Dimensions</td>\n",
      "        <td>Classes</td>\n",
      "        <td>Training, Validation, Testing</td>\n",
      "        <td>Processing</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "\t\t<td>IRIS</td>\n",
      "\t\t<td>150</td>\n",
      "\t\t<td>4</td>\n",
      "\t\t<td>3</td>\n",
      "        <td>n/a</td>\n",
      "        <td>3-Fold Stratified Cross Validation</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "        <td>DIGITS</td>\n",
      "        <td>1797</td>\n",
      "        <td>64</td>\n",
      "        <td>10</td>\n",
      "        <td>n/a</td>\n",
      "        <td>3-Fold Stratified Cross Validation</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "\t\t<td>MADELON*</td>\n",
      "\t\t<td>2600</td>\n",
      "\t\t<td>500</td>\n",
      "\t\t<td>2</td>\n",
      "        <td>2000, 600</td>\n",
      "        <td>3-Fold Stratified Cross Validation</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "\t\t<td>GISETTE*</td>\n",
      "\t\t<td>7000</td>\n",
      "\t\t<td>5000</td>\n",
      "\t\t<td>2</td>\n",
      "        <td>6000, 1000</td>\n",
      "        <td>Training [0:5000], Validation [5000:]</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "\t\t<td>HAR*</td>\n",
      "\t\t<td>10299</td>\n",
      "\t\t<td>561</td>\n",
      "\t\t<td>6</td>\n",
      "        <td>7352, 2946</td>\n",
      "        <td>Training [0:7352], Validation [7352:]</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "\t\t<td>LETTER</td>\n",
      "\t\t<td>20000</td>\n",
      "\t\t<td>16</td>\n",
      "\t\t<td>26</td>\n",
      "        <td>16000, 4000</td>\n",
      "        <td>Training [0:16000], Validation [16000:]</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "\t\t<td>COVTYPE</td>\n",
      "\t\t<td>581012</td>\n",
      "\t\t<td>54</td>\n",
      "\t\t<td>7</td>\n",
      "        <td>11340, 3780, 565892</td>\n",
      "        <td>Training [0:11340], Validation [11340:]</td>\n",
      "    </tr>\n",
      "</table>\n",
      "\n",
      "\\* indicates priority"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Algorithms\n",
      "\n",
      "### Support Vector Machine (SVM)\n",
      "\n",
      "#### Parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table_html = '<table><tr><td>Kernel</td><td>Degree</td><td>Width/Gamma</td><td>C-Value</td></tr>'\n",
      "\n",
      "for degree in [2, 3]:\n",
      "    for C in np.logspace(-9, 5, 6):\n",
      "        table_html += '<tr><td>poly</td><td>{:}</td><td></td><td>{:}</td></tr>'.format(degree, C)\n",
      "\n",
      "for width in [0.001, 0.01, 0.1, 1, 2]:\n",
      "    for C in np.logspace(-9, 5, 6):\n",
      "        table_html += '<tr><td>rbf</td><td></td><td>{:}</td><td>{:}</td></tr>'.format(width, C)\n",
      "\n",
      "table_html += '</table>'\n",
      "        \n",
      "display_html(table_html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><td>Kernel</td><td>Degree</td><td>Width/Gamma</td><td>C-Value</td></tr><tr><td>poly</td><td>2</td><td></td><td>1e-09</td></tr><tr><td>poly</td><td>2</td><td></td><td>6.3095734448e-07</td></tr><tr><td>poly</td><td>2</td><td></td><td>0.000398107170553</td></tr><tr><td>poly</td><td>2</td><td></td><td>0.251188643151</td></tr><tr><td>poly</td><td>2</td><td></td><td>158.489319246</td></tr><tr><td>poly</td><td>2</td><td></td><td>100000.0</td></tr><tr><td>poly</td><td>3</td><td></td><td>1e-09</td></tr><tr><td>poly</td><td>3</td><td></td><td>6.3095734448e-07</td></tr><tr><td>poly</td><td>3</td><td></td><td>0.000398107170553</td></tr><tr><td>poly</td><td>3</td><td></td><td>0.251188643151</td></tr><tr><td>poly</td><td>3</td><td></td><td>158.489319246</td></tr><tr><td>poly</td><td>3</td><td></td><td>100000.0</td></tr><tr><td>rbf</td><td></td><td>0.001</td><td>1e-09</td></tr><tr><td>rbf</td><td></td><td>0.001</td><td>6.3095734448e-07</td></tr><tr><td>rbf</td><td></td><td>0.001</td><td>0.000398107170553</td></tr><tr><td>rbf</td><td></td><td>0.001</td><td>0.251188643151</td></tr><tr><td>rbf</td><td></td><td>0.001</td><td>158.489319246</td></tr><tr><td>rbf</td><td></td><td>0.001</td><td>100000.0</td></tr><tr><td>rbf</td><td></td><td>0.01</td><td>1e-09</td></tr><tr><td>rbf</td><td></td><td>0.01</td><td>6.3095734448e-07</td></tr><tr><td>rbf</td><td></td><td>0.01</td><td>0.000398107170553</td></tr><tr><td>rbf</td><td></td><td>0.01</td><td>0.251188643151</td></tr><tr><td>rbf</td><td></td><td>0.01</td><td>158.489319246</td></tr><tr><td>rbf</td><td></td><td>0.01</td><td>100000.0</td></tr><tr><td>rbf</td><td></td><td>0.1</td><td>1e-09</td></tr><tr><td>rbf</td><td></td><td>0.1</td><td>6.3095734448e-07</td></tr><tr><td>rbf</td><td></td><td>0.1</td><td>0.000398107170553</td></tr><tr><td>rbf</td><td></td><td>0.1</td><td>0.251188643151</td></tr><tr><td>rbf</td><td></td><td>0.1</td><td>158.489319246</td></tr><tr><td>rbf</td><td></td><td>0.1</td><td>100000.0</td></tr><tr><td>rbf</td><td></td><td>1</td><td>1e-09</td></tr><tr><td>rbf</td><td></td><td>1</td><td>6.3095734448e-07</td></tr><tr><td>rbf</td><td></td><td>1</td><td>0.000398107170553</td></tr><tr><td>rbf</td><td></td><td>1</td><td>0.251188643151</td></tr><tr><td>rbf</td><td></td><td>1</td><td>158.489319246</td></tr><tr><td>rbf</td><td></td><td>1</td><td>100000.0</td></tr><tr><td>rbf</td><td></td><td>2</td><td>1e-09</td></tr><tr><td>rbf</td><td></td><td>2</td><td>6.3095734448e-07</td></tr><tr><td>rbf</td><td></td><td>2</td><td>0.000398107170553</td></tr><tr><td>rbf</td><td></td><td>2</td><td>0.251188643151</td></tr><tr><td>rbf</td><td></td><td>2</td><td>158.489319246</td></tr><tr><td>rbf</td><td></td><td>2</td><td>100000.0</td></tr></table>"
       ],
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x1f6dc50>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## k-Nearest-Neighbors\n",
      "\n",
      "### Parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table_html = '<table><tr><td>Neighbors</td><td>Width</td></tr>'\n",
      "\n",
      "for width in np.arange(0.1, 820+1, (820-0.1)/9):\n",
      "    table_html += '<tr><td>1000</td><td>{:}</td>'.format(width, C)\n",
      "\n",
      "table_html += '</table>'\n",
      "        \n",
      "display_html(table_html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><td>Neighbors</td><td>Width</td></tr><tr><td>1000</td><td>0.1</td><tr><td>1000</td><td>91.2</td><tr><td>1000</td><td>182.3</td><tr><td>1000</td><td>273.4</td><tr><td>1000</td><td>364.5</td><tr><td>1000</td><td>455.6</td><tr><td>1000</td><td>546.7</td><tr><td>1000</td><td>637.8</td><tr><td>1000</td><td>728.9</td><tr><td>1000</td><td>820.0</td></table>"
       ],
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x1f6b110>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}